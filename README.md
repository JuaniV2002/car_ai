# Extractor de Datos de Siniestros con IA

Este proyecto implementa un sistema inteligente para extraer informaci√≥n estructurada a partir de descripciones de accidentes de tr√°nsito no estructuradas (texto libre). Combina t√©cnicas de **Fuzzing** para la generaci√≥n de datos sint√©ticos y **LLMs (Modelos de Lenguaje Grande)** para el procesamiento de informaci√≥n.

## üéØ Objetivo

Demostrar la capacidad de los LLMs para "limpiar" y estructurar datos ruidosos del mundo real, una tarea que ser√≠a imposible con expresiones regulares (Regex) o SQL tradicional.

El sistema toma descripciones informales como:
> *"Tuve un accidente en av libertador ayer un ford fiesta me ray√≥ el costado a mi honda civic necesito gr√∫a"*

Y las convierte en JSON estructurado:
```json
{
  "fecha": "2024-03-18",
  "ubicacion": "Av. Libertador",
  "vehiculo_asegurado": "Honda Civic",
  "vehiculo_tercero": "Ford Fiesta",
  "responsabilidad_aparente": "tercero"
}
```

## üèóÔ∏è Arquitectura del Proyecto

El proyecto consta de tres m√≥dulos principales:

1.  **Generaci√≥n de Datos (Fuzzing):**
    *   Script: `fuzzing/generate_claims.py`
    *   Genera reclamos sint√©ticos inyectando "ruido" intencional: errores de ortograf√≠a, falta de puntuaci√≥n, jerga ("me choc√≥ de atr√°s"), y formatos de fecha variados.
    *   Simula la variabilidad de datos reales ingresados por usuarios.

2.  **Procesamiento con IA:**
    *   Script: `src/process_claims.py`
    *   Utiliza **Ollama** con el modelo **Llama 3.2**.
    *   Implementa un *System Prompt* robusto dise√±ado para inferir roles (qui√©n choc√≥ a qui√©n) y normalizar entidades.

3.  **Validaci√≥n y M√©tricas:**
    *   Script: `src/validate_results.py`
    *   Compara la salida del LLM contra el "Ground Truth" (la verdad absoluta generada por el fuzzer).
    *   Calcula precisi√≥n por campo y detecta errores l√≥gicos (como intercambiar veh√≠culos).

## üöÄ C√≥mo Ejecutar

### Prerrequisitos
- Python 3
- Ollama instalado y ejecut√°ndose (`ollama serve`)
- Modelo Llama 3.2 (`ollama pull llama3.2`)

### Pasos

1.  **Generar Datos de Prueba:**
    ```bash
    python3 fuzzing/generate_claims.py
    ```
    *Esto crear√° `data/synthetic_claims.jsonl` con 50 casos de prueba.*

2.  **Ejecutar el Extractor:**
    ```bash
    python3 src/process_claims.py
    ```
    *Procesar√° los reclamos y guardar√° los resultados en `data/processed_claims.jsonl`.*

3.  **Ver Resultados y M√©tricas:**
    ```bash
    python3 src/validate_results.py
    ```
    *Mostrar√° una tabla comparativa y el porcentaje de precisi√≥n.*

## üìä Resultados Obtenidos

En pruebas locales con Llama 3.2 (3B par√°metros), el sistema logr√≥:
- **100%** de precisi√≥n en detecci√≥n de Ubicaci√≥n.
- **98%** de precisi√≥n en identificaci√≥n de Veh√≠culos.
- **98%** de precisi√≥n en asignaci√≥n de Responsabilidad.

*Ver el reporte completo en `metrics_report.md`.*

## üõ†Ô∏è Tecnolog√≠as Utilizadas

- **Python 3**: Lenguaje principal.
- **Ollama**: Runtime local para LLMs.
- **Llama 3.2**: Modelo de lenguaje optimizado para instrucciones.
- **JSONL**: Formato de datos para procesamiento eficiente.

---
*Proyecto desarrollado para la materia de Inteligencia Artificial.*